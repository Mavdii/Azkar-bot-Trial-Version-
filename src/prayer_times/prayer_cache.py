#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ğŸ•Œ Prayer Times Cache System - Ù†Ø¸Ø§Ù… Ø§Ù„ØªØ®Ø²ÙŠÙ† Ø§Ù„Ù…Ø¤Ù‚Øª Ù„Ù…ÙˆØ§Ù‚ÙŠØª Ø§Ù„ØµÙ„Ø§Ø©
====================================================================
Ù†Ø¸Ø§Ù… ØªØ®Ø²ÙŠÙ† Ù…Ø¤Ù‚Øª Ù…ØªÙ‚Ø¯Ù… Ù„Ù…ÙˆØ§Ù‚ÙŠØª Ø§Ù„ØµÙ„Ø§Ø© Ù…Ø¹ Ø¯Ø¹Ù… Ù…Ù„ÙØ§Øª ÙˆÙ‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª

Features:
- ğŸ’¾ ØªØ®Ø²ÙŠÙ† Ù…Ø¤Ù‚Øª Ù„Ù…Ø¯Ø© 24 Ø³Ø§Ø¹Ø©
- ğŸ”„ ØªÙ†Ø¸ÙŠÙ ØªÙ„Ù‚Ø§Ø¦ÙŠ Ù„Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ù†ØªÙ‡ÙŠØ© Ø§Ù„ØµÙ„Ø§Ø­ÙŠØ©
- ğŸ“ Ø¯Ø¹Ù… Ø§Ù„ØªØ®Ø²ÙŠÙ† ÙÙŠ Ø§Ù„Ù…Ù„ÙØ§Øª ÙˆÙ‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
- ğŸ›¡ï¸ Ø¢Ù„ÙŠØ© fallback Ù„Ù„Ø£ÙŠØ§Ù… Ø§Ù„Ø³Ø§Ø¨Ù‚Ø©
- ğŸ“Š Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ù…ÙØµÙ„Ø© Ù„Ù„Ø£Ø¯Ø§Ø¡

Author: Islamic Bot Developer Team
Version: 1.0.0
License: MIT
"""

import asyncio
import json
import logging
import os
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Any, Union
import pytz
from dataclasses import dataclass
import aiofiles
from pathlib import Path

# Import the CairoPrayerTimes model
from .cairo_manager import CairoPrayerTimes

# Configure logging
logger = logging.getLogger(__name__)

# Cairo timezone
CAIRO_TZ = pytz.timezone('Africa/Cairo')

@dataclass
class CacheEntry:
    """Ø¥Ø¯Ø®Ø§Ù„ Ø§Ù„ØªØ®Ø²ÙŠÙ† Ø§Ù„Ù…Ø¤Ù‚Øª"""
    date: str
    prayer_times: CairoPrayerTimes
    cached_at: datetime
    expires_at: datetime
    source: str
    
    def is_expired(self) -> bool:
        """Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù†ØªÙ‡Ø§Ø¡ ØµÙ„Ø§Ø­ÙŠØ© Ø§Ù„Ø¥Ø¯Ø®Ø§Ù„"""
        return datetime.now(CAIRO_TZ) > self.expires_at
    
    def to_dict(self) -> Dict[str, Any]:
        """ØªØ­ÙˆÙŠÙ„ Ø¥Ù„Ù‰ Ù‚Ø§Ù…ÙˆØ³"""
        return {
            'date': self.date,
            'prayer_times': self.prayer_times.to_dict(),
            'cached_at': self.cached_at.isoformat(),
            'expires_at': self.expires_at.isoformat(),
            'source': self.source
        }
    
    @classmethod
    def from_dict(cls, data: Dict[str, Any]) -> 'CacheEntry':
        """Ø¥Ù†Ø´Ø§Ø¡ Ù…Ù† Ù‚Ø§Ù…ÙˆØ³"""
        return cls(
            date=data['date'],
            prayer_times=CairoPrayerTimes.from_dict(data['prayer_times']),
            cached_at=datetime.fromisoformat(data['cached_at']),
            expires_at=datetime.fromisoformat(data['expires_at']),
            source=data['source']
        )

class PrayerTimesCache:
    """Ù†Ø¸Ø§Ù… Ø§Ù„ØªØ®Ø²ÙŠÙ† Ø§Ù„Ù…Ø¤Ù‚Øª Ù„Ù…ÙˆØ§Ù‚ÙŠØª Ø§Ù„ØµÙ„Ø§Ø©"""
    
    def __init__(
        self,
        cache_file: str = "prayer_times_cache.json",
        cache_duration_hours: int = 24,
        max_entries: int = 100,
        cleanup_interval_hours: int = 6,
        supabase_client=None
    ):
        self.cache_file = Path(cache_file)
        self.cache_duration_hours = cache_duration_hours
        self.max_entries = max_entries
        self.cleanup_interval_hours = cleanup_interval_hours
        self.supabase_client = supabase_client
        
        # Ø§Ù„ØªØ®Ø²ÙŠÙ† Ø§Ù„Ù…Ø¤Ù‚Øª ÙÙŠ Ø§Ù„Ø°Ø§ÙƒØ±Ø©
        self.memory_cache: Dict[str, CacheEntry] = {}
        
        # Ù…Ù‡Ù…Ø© Ø§Ù„ØªÙ†Ø¸ÙŠÙ Ø§Ù„ØªÙ„Ù‚Ø§Ø¦ÙŠ
        self.cleanup_task: Optional[asyncio.Task] = None
        
        # Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª
        self.stats = {
            'total_requests': 0,
            'cache_hits': 0,
            'cache_misses': 0,
            'file_reads': 0,
            'file_writes': 0,
            'db_reads': 0,
            'db_writes': 0,
            'cleanup_runs': 0,
            'entries_cleaned': 0,
            'last_cleanup': None
        }
    
    async def initialize(self) -> bool:
        """ØªÙ‡ÙŠØ¦Ø© Ù†Ø¸Ø§Ù… Ø§Ù„ØªØ®Ø²ÙŠÙ† Ø§Ù„Ù…Ø¤Ù‚Øª"""
        try:
            logger.info("ğŸ”„ Ø¨Ø¯Ø¡ ØªÙ‡ÙŠØ¦Ø© Ù†Ø¸Ø§Ù… Ø§Ù„ØªØ®Ø²ÙŠÙ† Ø§Ù„Ù…Ø¤Ù‚Øª...")
            
            # Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø¬Ù„Ø¯ Ø§Ù„ØªØ®Ø²ÙŠÙ† Ø§Ù„Ù…Ø¤Ù‚Øª Ø¥Ø°Ø§ Ù„Ù… ÙŠÙƒÙ† Ù…ÙˆØ¬ÙˆØ¯Ø§Ù‹
            self.cache_file.parent.mkdir(parents=True, exist_ok=True)
            
            # ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø­ÙÙˆØ¸Ø©
            await self._load_from_file()
            
            # Ø¨Ø¯Ø¡ Ù…Ù‡Ù…Ø© Ø§Ù„ØªÙ†Ø¸ÙŠÙ Ø§Ù„ØªÙ„Ù‚Ø§Ø¦ÙŠ
            await self._start_cleanup_task()
            
            logger.info("âœ… ØªÙ… ØªÙ‡ÙŠØ¦Ø© Ù†Ø¸Ø§Ù… Ø§Ù„ØªØ®Ø²ÙŠÙ† Ø§Ù„Ù…Ø¤Ù‚Øª Ø¨Ù†Ø¬Ø§Ø­")
            return True
            
        except Exception as e:
            logger.error(f"âŒ ÙØ´Ù„ ÙÙŠ ØªÙ‡ÙŠØ¦Ø© Ù†Ø¸Ø§Ù… Ø§Ù„ØªØ®Ø²ÙŠÙ† Ø§Ù„Ù…Ø¤Ù‚Øª: {e}")
            return False
    
    async def get_cached_times(self, date: str) -> Optional[CairoPrayerTimes]:
        """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ù…ÙˆØ§Ù‚ÙŠØª Ù…Ø­ÙÙˆØ¸Ø© Ù„ØªØ§Ø±ÙŠØ® Ù…Ø­Ø¯Ø¯"""
        self.stats['total_requests'] += 1
        
        try:
            # Ø§Ù„Ø¨Ø­Ø« ÙÙŠ Ø§Ù„Ø°Ø§ÙƒØ±Ø© Ø£ÙˆÙ„Ø§Ù‹
            if date in self.memory_cache:
                entry = self.memory_cache[date]
                if not entry.is_expired():
                    self.stats['cache_hits'] += 1
                    logger.debug(f"ğŸ“¦ ØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ù…ÙˆØ§Ù‚ÙŠØª {date} ÙÙŠ Ø§Ù„Ø°Ø§ÙƒØ±Ø©")
                    return entry.prayer_times
                else:
                    # Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ø¥Ø¯Ø®Ø§Ù„ Ø§Ù„Ù…Ù†ØªÙ‡ÙŠ Ø§Ù„ØµÙ„Ø§Ø­ÙŠØ©
                    del self.memory_cache[date]
                    logger.debug(f"ğŸ—‘ï¸ ØªÙ… Ø­Ø°Ù Ø¥Ø¯Ø®Ø§Ù„ Ù…Ù†ØªÙ‡ÙŠ Ø§Ù„ØµÙ„Ø§Ø­ÙŠØ©: {date}")
            
            # Ø§Ù„Ø¨Ø­Ø« ÙÙŠ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
            if self.supabase_client:
                db_entry = await self._get_from_database(date)
                if db_entry and not db_entry.is_expired():
                    # Ø¥Ø¶Ø§ÙØ© Ø¥Ù„Ù‰ Ø§Ù„Ø°Ø§ÙƒØ±Ø©
                    self.memory_cache[date] = db_entry
                    self.stats['cache_hits'] += 1
                    self.stats['db_reads'] += 1
                    logger.debug(f"ğŸ“¦ ØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ù…ÙˆØ§Ù‚ÙŠØª {date} ÙÙŠ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª")
                    return db_entry.prayer_times
            
            # Ø§Ù„Ø¨Ø­Ø« ÙÙŠ Ø§Ù„Ù…Ù„Ù
            file_entry = await self._get_from_file(date)
            if file_entry and not file_entry.is_expired():
                # Ø¥Ø¶Ø§ÙØ© Ø¥Ù„Ù‰ Ø§Ù„Ø°Ø§ÙƒØ±Ø©
                self.memory_cache[date] = file_entry
                self.stats['cache_hits'] += 1
                self.stats['file_reads'] += 1
                logger.debug(f"ğŸ“¦ ØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ù…ÙˆØ§Ù‚ÙŠØª {date} ÙÙŠ Ø§Ù„Ù…Ù„Ù")
                return file_entry.prayer_times
            
            # Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø¨ÙŠØ§Ù†Ø§Øª ØµØ§Ù„Ø­Ø©
            self.stats['cache_misses'] += 1
            logger.debug(f"âŒ Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ù…ÙˆØ§Ù‚ÙŠØª ØµØ§Ù„Ø­Ø© Ù„Ù€ {date}")
            return None
            
        except Exception as e:
            self.stats['cache_misses'] += 1
            logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø¬Ù„Ø¨ Ù…ÙˆØ§Ù‚ÙŠØª {date} Ù…Ù† Ø§Ù„ØªØ®Ø²ÙŠÙ† Ø§Ù„Ù…Ø¤Ù‚Øª: {e}")
            return None
    
    async def set_cached_times(self, date: str, prayer_times: CairoPrayerTimes) -> bool:
        """Ø­ÙØ¸ Ù…ÙˆØ§Ù‚ÙŠØª ÙÙŠ Ø§Ù„ØªØ®Ø²ÙŠÙ† Ø§Ù„Ù…Ø¤Ù‚Øª"""
        try:
            now = datetime.now(CAIRO_TZ)
            expires_at = now + timedelta(hours=self.cache_duration_hours)
            
            # Ø¥Ù†Ø´Ø§Ø¡ Ø¥Ø¯Ø®Ø§Ù„ Ø¬Ø¯ÙŠØ¯
            entry = CacheEntry(
                date=date,
                prayer_times=prayer_times,
                cached_at=now,
                expires_at=expires_at,
                source=prayer_times.source
            )
            
            # Ø­ÙØ¸ ÙÙŠ Ø§Ù„Ø°Ø§ÙƒØ±Ø©
            self.memory_cache[date] = entry
            
            # Ø­ÙØ¸ ÙÙŠ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
            if self.supabase_client:
                await self._save_to_database(entry)
                self.stats['db_writes'] += 1
            
            # Ø­ÙØ¸ ÙÙŠ Ø§Ù„Ù…Ù„Ù
            await self._save_to_file()
            self.stats['file_writes'] += 1
            
            # ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ø°Ø§ÙƒØ±Ø© Ø¥Ø°Ø§ ØªØ¬Ø§ÙˆØ²Øª Ø§Ù„Ø­Ø¯ Ø§Ù„Ø£Ù‚ØµÙ‰
            if len(self.memory_cache) > self.max_entries:
                await self._cleanup_memory_cache()
            
            logger.debug(f"âœ… ØªÙ… Ø­ÙØ¸ Ù…ÙˆØ§Ù‚ÙŠØª {date} ÙÙŠ Ø§Ù„ØªØ®Ø²ÙŠÙ† Ø§Ù„Ù…Ø¤Ù‚Øª")
            return True
            
        except Exception as e:
            logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø­ÙØ¸ Ù…ÙˆØ§Ù‚ÙŠØª {date}: {e}")
            return False
    
    async def get_last_valid_times(self, days_back: int = 7) -> Optional[CairoPrayerTimes]:
        """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø¢Ø®Ø± Ù…ÙˆØ§Ù‚ÙŠØª ØµØ§Ù„Ø­Ø© Ù…Ù† Ø§Ù„Ø£ÙŠØ§Ù… Ø§Ù„Ø³Ø§Ø¨Ù‚Ø©"""
        try:
            today = datetime.now(CAIRO_TZ).date()
            
            # Ø§Ù„Ø¨Ø­Ø« ÙÙŠ Ø§Ù„Ø£ÙŠØ§Ù… Ø§Ù„Ø³Ø§Ø¨Ù‚Ø©
            for i in range(1, days_back + 1):
                check_date = (today - timedelta(days=i)).isoformat()
                cached_times = await self.get_cached_times(check_date)
                
                if cached_times and cached_times.is_valid():
                    logger.info(f"ğŸ“¦ ØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ù…ÙˆØ§Ù‚ÙŠØª ØµØ§Ù„Ø­Ø© Ù…Ù† {check_date}")
                    return cached_times
            
            logger.warning(f"âš ï¸ Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ù…ÙˆØ§Ù‚ÙŠØª ØµØ§Ù„Ø­Ø© ÙÙŠ Ø¢Ø®Ø± {days_back} Ø£ÙŠØ§Ù…")
            return None
            
        except Exception as e:
            logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø¢Ø®Ø± Ù…ÙˆØ§Ù‚ÙŠØª ØµØ§Ù„Ø­Ø©: {e}")
            return None
    
    async def _get_from_file(self, date: str) -> Optional[CacheEntry]:
        """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø¥Ø¯Ø®Ø§Ù„ Ù…Ù† Ø§Ù„Ù…Ù„Ù"""
        try:
            if not self.cache_file.exists():
                return None
            
            async with aiofiles.open(self.cache_file, 'r', encoding='utf-8') as f:
                content = await f.read()
                if not content.strip():
                    return None
                
                data = json.loads(content)
                
                if date in data:
                    return CacheEntry.from_dict(data[date])
                
                return None
                
        except Exception as e:
            logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ù…Ù„Ù Ù„Ù„ØªØ§Ø±ÙŠØ® {date}: {e}")
            return None
    
    async def _save_to_file(self) -> bool:
        """Ø­ÙØ¸ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø¥Ø¯Ø®Ø§Ù„Ø§Øª ÙÙŠ Ø§Ù„Ù…Ù„Ù"""
        try:
            # ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ø°Ø§ÙƒØ±Ø© Ø¥Ù„Ù‰ Ù‚Ø§Ù…ÙˆØ³
            data = {}
            for date, entry in self.memory_cache.items():
                if not entry.is_expired():
                    data[date] = entry.to_dict()
            
            # Ø­ÙØ¸ ÙÙŠ Ø§Ù„Ù…Ù„Ù
            async with aiofiles.open(self.cache_file, 'w', encoding='utf-8') as f:
                await f.write(json.dumps(data, indent=2, ensure_ascii=False))
            
            logger.debug(f"âœ… ØªÙ… Ø­ÙØ¸ {len(data)} Ø¥Ø¯Ø®Ø§Ù„ ÙÙŠ Ø§Ù„Ù…Ù„Ù")
            return True
            
        except Exception as e:
            logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø­ÙØ¸ Ø§Ù„Ù…Ù„Ù: {e}")
            return False
    
    async def _load_from_file(self) -> bool:
        """ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ù† Ø§Ù„Ù…Ù„Ù"""
        try:
            if not self.cache_file.exists():
                logger.info("ğŸ“ Ù…Ù„Ù Ø§Ù„ØªØ®Ø²ÙŠÙ† Ø§Ù„Ù…Ø¤Ù‚Øª ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯ØŒ Ø³ÙŠØªÙ… Ø¥Ù†Ø´Ø§Ø¤Ù‡")
                return True
            
            async with aiofiles.open(self.cache_file, 'r', encoding='utf-8') as f:
                content = await f.read()
                if not content.strip():
                    return True
                
                data = json.loads(content)
                
                # ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¥Ø¯Ø®Ø§Ù„Ø§Øª Ø§Ù„ØµØ§Ù„Ø­Ø© ÙÙ‚Ø·
                loaded_count = 0
                for date, entry_data in data.items():
                    try:
                        entry = CacheEntry.from_dict(entry_data)
                        if not entry.is_expired():
                            self.memory_cache[date] = entry
                            loaded_count += 1
                    except Exception as e:
                        logger.warning(f"âš ï¸ ØªØ®Ø·ÙŠ Ø¥Ø¯Ø®Ø§Ù„ ØªØ§Ù„Ù Ù„Ù„ØªØ§Ø±ÙŠØ® {date}: {e}")
                
                logger.info(f"ğŸ“ ØªÙ… ØªØ­Ù…ÙŠÙ„ {loaded_count} Ø¥Ø¯Ø®Ø§Ù„ Ù…Ù† Ø§Ù„Ù…Ù„Ù")
                return True
                
        except Exception as e:
            logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…Ù„Ù: {e}")
            return False
    
    async def _get_from_database(self, date: str) -> Optional[CacheEntry]:
        """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø¥Ø¯Ø®Ø§Ù„ Ù…Ù† Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª"""
        try:
            if not self.supabase_client:
                return None
            
            result = self.supabase_client.table('prayer_times_cache').select('*').eq('date', date).execute()
            
            if result.data:
                db_data = result.data[0]
                
                # ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¥Ù„Ù‰ CacheEntry
                prayer_times_data = db_data['prayer_times']
                prayer_times = CairoPrayerTimes.from_dict(prayer_times_data)
                
                entry = CacheEntry(
                    date=db_data['date'],
                    prayer_times=prayer_times,
                    cached_at=datetime.fromisoformat(db_data['created_at']),
                    expires_at=datetime.fromisoformat(db_data['expires_at']),
                    source=db_data['source']
                )
                
                return entry
            
            return None
            
        except Exception as e:
            logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ù‚Ø±Ø§Ø¡Ø© Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù„Ù„ØªØ§Ø±ÙŠØ® {date}: {e}")
            return None
    
    async def _save_to_database(self, entry: CacheEntry) -> bool:
        """Ø­ÙØ¸ Ø¥Ø¯Ø®Ø§Ù„ ÙÙŠ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª"""
        try:
            if not self.supabase_client:
                return False
            
            # ØªØ­Ø¶ÙŠØ± Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
            data = {
                'date': entry.date,
                'prayer_times': entry.prayer_times.to_dict(),
                'source': entry.source,
                'created_at': entry.cached_at.isoformat(),
                'expires_at': entry.expires_at.isoformat()
            }
            
            # Ù…Ø­Ø§ÙˆÙ„Ø© Ø§Ù„ØªØ­Ø¯ÙŠØ« Ø£ÙˆÙ„Ø§Ù‹ØŒ Ø«Ù… Ø§Ù„Ø¥Ø¯Ø±Ø§Ø¬
            result = self.supabase_client.table('prayer_times_cache').upsert(data).execute()
            
            if result.data:
                logger.debug(f"âœ… ØªÙ… Ø­ÙØ¸ Ù…ÙˆØ§Ù‚ÙŠØª {entry.date} ÙÙŠ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª")
                return True
            else:
                logger.error(f"âŒ ÙØ´Ù„ ÙÙŠ Ø­ÙØ¸ Ù…ÙˆØ§Ù‚ÙŠØª {entry.date} ÙÙŠ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª")
                return False
                
        except Exception as e:
            logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø­ÙØ¸ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù„Ù„ØªØ§Ø±ÙŠØ® {entry.date}: {e}")
            return False
    
    async def _cleanup_memory_cache(self) -> None:
        """ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ø°Ø§ÙƒØ±Ø© Ù…Ù† Ø§Ù„Ø¥Ø¯Ø®Ø§Ù„Ø§Øª Ø§Ù„Ù‚Ø¯ÙŠÙ…Ø©"""
        try:
            # Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ø¥Ø¯Ø®Ø§Ù„Ø§Øª Ø§Ù„Ù…Ù†ØªÙ‡ÙŠØ© Ø§Ù„ØµÙ„Ø§Ø­ÙŠØ©
            expired_dates = [
                date for date, entry in self.memory_cache.items()
                if entry.is_expired()
            ]
            
            for date in expired_dates:
                del self.memory_cache[date]
            
            # Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ø¹Ø¯Ø¯ Ù„Ø§ ÙŠØ²Ø§Ù„ ÙƒØ¨ÙŠØ±Ø§Ù‹ØŒ Ø§Ø­ØªÙØ¸ Ø¨Ø§Ù„Ø£Ø­Ø¯Ø« ÙÙ‚Ø·
            if len(self.memory_cache) > self.max_entries:
                # ØªØ±ØªÙŠØ¨ Ø­Ø³Ø¨ ØªØ§Ø±ÙŠØ® Ø§Ù„ØªØ®Ø²ÙŠÙ† Ø§Ù„Ù…Ø¤Ù‚Øª
                sorted_entries = sorted(
                    self.memory_cache.items(),
                    key=lambda x: x[1].cached_at,
                    reverse=True
                )
                
                # Ø§Ù„Ø§Ø­ØªÙØ§Ø¸ Ø¨Ø§Ù„Ø£Ø­Ø¯Ø« ÙÙ‚Ø·
                self.memory_cache = dict(sorted_entries[:self.max_entries])
            
            cleaned_count = len(expired_dates)
            if cleaned_count > 0:
                self.stats['entries_cleaned'] += cleaned_count
                logger.debug(f"ğŸ—‘ï¸ ØªÙ… ØªÙ†Ø¸ÙŠÙ {cleaned_count} Ø¥Ø¯Ø®Ø§Ù„ Ù…Ù† Ø§Ù„Ø°Ø§ÙƒØ±Ø©")
                
        except Exception as e:
            logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ø°Ø§ÙƒØ±Ø©: {e}")
    
    async def cleanup_expired(self) -> int:
        """ØªÙ†Ø¸ÙŠÙ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø¥Ø¯Ø®Ø§Ù„Ø§Øª Ø§Ù„Ù…Ù†ØªÙ‡ÙŠØ© Ø§Ù„ØµÙ„Ø§Ø­ÙŠØ©"""
        try:
            self.stats['cleanup_runs'] += 1
            self.stats['last_cleanup'] = datetime.now().isoformat()
            
            cleaned_count = 0
            
            # ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ø°Ø§ÙƒØ±Ø©
            await self._cleanup_memory_cache()
            
            # ØªÙ†Ø¸ÙŠÙ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
            if self.supabase_client:
                try:
                    now = datetime.now(CAIRO_TZ).isoformat()
                    result = self.supabase_client.table('prayer_times_cache').delete().lt('expires_at', now).execute()
                    if result.data:
                        db_cleaned = len(result.data)
                        cleaned_count += db_cleaned
                        logger.debug(f"ğŸ—‘ï¸ ØªÙ… ØªÙ†Ø¸ÙŠÙ {db_cleaned} Ø¥Ø¯Ø®Ø§Ù„ Ù…Ù† Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª")
                except Exception as e:
                    logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ ØªÙ†Ø¸ÙŠÙ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª: {e}")
            
            # Ø­ÙØ¸ Ø§Ù„Ù…Ù„Ù Ø¨Ø¹Ø¯ Ø§Ù„ØªÙ†Ø¸ÙŠÙ
            await self._save_to_file()
            
            logger.info(f"ğŸ—‘ï¸ ØªÙ… ØªÙ†Ø¸ÙŠÙ {cleaned_count} Ø¥Ø¯Ø®Ø§Ù„ Ù…Ù†ØªÙ‡ÙŠ Ø§Ù„ØµÙ„Ø§Ø­ÙŠØ©")
            return cleaned_count
            
        except Exception as e:
            logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ø¥Ø¯Ø®Ø§Ù„Ø§Øª Ø§Ù„Ù…Ù†ØªÙ‡ÙŠØ© Ø§Ù„ØµÙ„Ø§Ø­ÙŠØ©: {e}")
            return 0
    
    async def _start_cleanup_task(self) -> None:
        """Ø¨Ø¯Ø¡ Ù…Ù‡Ù…Ø© Ø§Ù„ØªÙ†Ø¸ÙŠÙ Ø§Ù„ØªÙ„Ù‚Ø§Ø¦ÙŠ"""
        try:
            async def cleanup_loop():
                while True:
                    try:
                        # Ø§Ù†ØªØ¸Ø§Ø± ÙØªØ±Ø© Ø§Ù„ØªÙ†Ø¸ÙŠÙ
                        await asyncio.sleep(self.cleanup_interval_hours * 3600)
                        
                        # ØªÙ†ÙÙŠØ° Ø§Ù„ØªÙ†Ø¸ÙŠÙ
                        await self.cleanup_expired()
                        
                    except Exception as e:
                        logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ù…Ù‡Ù…Ø© Ø§Ù„ØªÙ†Ø¸ÙŠÙ Ø§Ù„ØªÙ„Ù‚Ø§Ø¦ÙŠ: {e}")
                        await asyncio.sleep(3600)  # Ø§Ù†ØªØ¸Ø§Ø± Ø³Ø§Ø¹Ø© Ù‚Ø¨Ù„ Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø© Ù…Ø±Ø© Ø£Ø®Ø±Ù‰
            
            self.cleanup_task = asyncio.create_task(cleanup_loop())
            logger.info(f"âœ… ØªÙ… Ø¨Ø¯Ø¡ Ù…Ù‡Ù…Ø© Ø§Ù„ØªÙ†Ø¸ÙŠÙ Ø§Ù„ØªÙ„Ù‚Ø§Ø¦ÙŠ (ÙƒÙ„ {self.cleanup_interval_hours} Ø³Ø§Ø¹Ø§Øª)")
            
        except Exception as e:
            logger.error(f"âŒ ÙØ´Ù„ ÙÙŠ Ø¨Ø¯Ø¡ Ù…Ù‡Ù…Ø© Ø§Ù„ØªÙ†Ø¸ÙŠÙ Ø§Ù„ØªÙ„Ù‚Ø§Ø¦ÙŠ: {e}")
    
    def get_statistics(self) -> Dict[str, Any]:
        """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„ØªØ®Ø²ÙŠÙ† Ø§Ù„Ù…Ø¤Ù‚Øª"""
        try:
            # Ø­Ø³Ø§Ø¨ Ù…Ø¹Ø¯Ù„ Ø§Ù„Ù†Ø¬Ø§Ø­
            hit_rate = (
                (self.stats['cache_hits'] / self.stats['total_requests'] * 100)
                if self.stats['total_requests'] > 0 else 0
            )
            
            return {
                'cache_stats': {
                    'total_requests': self.stats['total_requests'],
                    'cache_hits': self.stats['cache_hits'],
                    'cache_misses': self.stats['cache_misses'],
                    'hit_rate_percentage': round(hit_rate, 2),
                    'memory_entries': len(self.memory_cache),
                    'max_entries': self.max_entries
                },
                'storage_stats': {
                    'file_reads': self.stats['file_reads'],
                    'file_writes': self.stats['file_writes'],
                    'db_reads': self.stats['db_reads'],
                    'db_writes': self.stats['db_writes']
                },
                'cleanup_stats': {
                    'cleanup_runs': self.stats['cleanup_runs'],
                    'entries_cleaned': self.stats['entries_cleaned'],
                    'last_cleanup': self.stats['last_cleanup'],
                    'cleanup_task_running': self.cleanup_task is not None and not self.cleanup_task.done()
                }
            }
            
        except Exception as e:
            logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„ØªØ®Ø²ÙŠÙ† Ø§Ù„Ù…Ø¤Ù‚Øª: {e}")
            return {}
    
    def get_cache_info(self) -> Dict[str, Any]:
        """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„ØªØ®Ø²ÙŠÙ† Ø§Ù„Ù…Ø¤Ù‚Øª"""
        try:
            # Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ø¥Ø¯Ø®Ø§Ù„Ø§Øª Ø§Ù„Ø­Ø§Ù„ÙŠØ©
            entries_info = []
            for date, entry in self.memory_cache.items():
                entries_info.append({
                    'date': date,
                    'source': entry.source,
                    'cached_at': entry.cached_at.isoformat(),
                    'expires_at': entry.expires_at.isoformat(),
                    'is_expired': entry.is_expired(),
                    'hours_until_expiry': (
                        (entry.expires_at - datetime.now(CAIRO_TZ)).total_seconds() / 3600
                        if not entry.is_expired() else 0
                    )
                })
            
            return {
                'cache_file': str(self.cache_file),
                'cache_duration_hours': self.cache_duration_hours,
                'entries': entries_info,
                'total_entries': len(entries_info),
                'expired_entries': len([e for e in entries_info if e['is_expired']])
            }
            
        except Exception as e:
            logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„ØªØ®Ø²ÙŠÙ† Ø§Ù„Ù…Ø¤Ù‚Øª: {e}")
            return {}
    
    async def clear_cache(self) -> bool:
        """Ù…Ø³Ø­ Ø¬Ù…ÙŠØ¹ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ®Ø²ÙŠÙ† Ø§Ù„Ù…Ø¤Ù‚Øª"""
        try:
            # Ù…Ø³Ø­ Ø§Ù„Ø°Ø§ÙƒØ±Ø©
            self.memory_cache.clear()
            
            # Ù…Ø³Ø­ Ø§Ù„Ù…Ù„Ù
            if self.cache_file.exists():
                self.cache_file.unlink()
            
            # Ù…Ø³Ø­ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
            if self.supabase_client:
                self.supabase_client.table('prayer_times_cache').delete().neq('id', 0).execute()
            
            logger.info("ğŸ—‘ï¸ ØªÙ… Ù…Ø³Ø­ Ø¬Ù…ÙŠØ¹ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ®Ø²ÙŠÙ† Ø§Ù„Ù…Ø¤Ù‚Øª")
            return True
            
        except Exception as e:
            logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ù…Ø³Ø­ Ø§Ù„ØªØ®Ø²ÙŠÙ† Ø§Ù„Ù…Ø¤Ù‚Øª: {e}")
            return False
    
    async def cleanup(self) -> None:
        """ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ù…ÙˆØ§Ø±Ø¯"""
        try:
            # Ø¥ÙŠÙ‚Ø§Ù Ù…Ù‡Ù…Ø© Ø§Ù„ØªÙ†Ø¸ÙŠÙ
            if self.cleanup_task and not self.cleanup_task.done():
                self.cleanup_task.cancel()
                try:
                    await self.cleanup_task
                except asyncio.CancelledError:
                    pass
            
            # Ø­ÙØ¸ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø£Ø®ÙŠØ±Ø©
            await self._save_to_file()
            
            logger.info("âœ… ØªÙ… ØªÙ†Ø¸ÙŠÙ Ù†Ø¸Ø§Ù… Ø§Ù„ØªØ®Ø²ÙŠÙ† Ø§Ù„Ù…Ø¤Ù‚Øª")
            
        except Exception as e:
            logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ ØªÙ†Ø¸ÙŠÙ Ù†Ø¸Ø§Ù… Ø§Ù„ØªØ®Ø²ÙŠÙ† Ø§Ù„Ù…Ø¤Ù‚Øª: {e}")
    
    def __str__(self) -> str:
        return f"PrayerTimesCache(entries={len(self.memory_cache)}, hit_rate={self.stats['cache_hits']}/{self.stats['total_requests']})"
    
    def __repr__(self) -> str:
        return f"PrayerTimesCache(file={self.cache_file}, duration={self.cache_duration_hours}h, max_entries={self.max_entries})"


# Export Ù„Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù… ÙÙŠ Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ø£Ø®Ø±Ù‰
__all__ = ['PrayerTimesCache', 'CacheEntry']